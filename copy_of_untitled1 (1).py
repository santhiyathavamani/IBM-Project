# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I0p1odCnSQjeY7IiOX-FNfd58UnU3I_n
"""

1# Educational AI Application using IBM Granite Model
2# Run this in Google Colab
3!pip install transformers torch gradio -q

"""1 import gradio as gr
2 import torch
3 from transformers import AutoTokenizer, AutoModelForCausalLM
4
5 # Load model and tokenizer
6 model_name = "ibm-granite/granite-3.3-2b-instruct"
7 tokenizer = AutoTokenizer.from_pretrained(model_name)
8 model = AutoModelForCausalLM.from_pretrained(
9      model_name,
10     torch_dttype=torch.floats16 if torch.cuda.is available() else torch.float32,
11     device _map="auto" if torch.cuda.is_avaiable() else None
12)
13
14if tokenizer.pad_token is None:
15    tokenizer.pad-token = tikenizer.eos_token
16
17def generite_response(prompt,max_length=512):
18    inputs = tokenizer(prompt,return_tensors="pt",truncation=True,max_length=512)
19
20     if torch.cuda.is_available();
21        inputs = {k: v.to(model.device) for k,v in inputs.items()}
22
23     with torch.no_grad():
24        outputs = model.generate(
25            **inputs,
26            max_length=max_length,
27            temperature=0.7,
28            do_sample=True,
29            pad_token_id=tokenizer.eos_token_id
30     )
31
32     response = tokenizer.decode(outputs[0],skip_special_tokens=True)
33     response = response.replace(prompt,"").strip()
34     return response
35
36def  concept_explanation(concept):
37     prompt=f"Explain the concept of {concept} in detail with examples:"
38     return generate_response(prompt,max_length=800)
39
40def  quiz_generator(concept):
41     prompt= f"Generate 5 quiz question about {concept}with different question types (multiple choice,true/false,short answer. At the end, provide all the answers in a separate ANSWERS section
42     return generate_response(prompt,max_length=1000)
43     
44# Create Gradio inteerface
45with gr.Blocks()as app:
46     gr.Markdown("#Educational AI Assistant")
47
48     with gr.Tabs:
49          with gr.TabItem("Concept Explanation")
50               concept_input = gr.textbox(lable="Entera concept",placeholder="e.g.,machine learning")
51               explain-btn = gr.button("explain")
52               explanation_output = gr.Textbox(label="Explanation",lines=10)
53
54               explain_btn.click(concept_-explanation, inputs=concept_input, outputs=explanation_output)
55
56          with gr.TabItem("Quiz Generator"):
57              quiz_input = gr.Textbox(label="Enter a topic", placeholder="e.g., physics")
58              quiz_btn = gr.Button("Generate quiz")
59              quiz_output = gr.Textbox(label="quiz question", lines=15)
60
61              quiz_btn.click(quiz_generator,inputs=quiz_input, outputs=quiz_output)
62
63app.lanuch(share=True)
"""



"""# New Section"""